# 目录

- [1.图像编辑模型涵盖哪些细粒度的编辑任务？](#1.图像编辑模型涵盖哪些细粒度的编辑任务？)
- [2.图像编辑模型的主要技术路线有哪些？](#2.图像编辑模型的主要技术路线有哪些？)
- [3.在图像编辑的定量评估中，常用的基准测试和性能指标是什么？](#3.在图像编辑的定量评估中，常用的基准测试和性能指标是什么？)
- [4.Step1X-Edit 通用图像编辑框架是如何构建其大规模、多任务的编辑数据集](#4.Step1X-Edit-通用图像编辑框架是如何构建其大规模、多任务的编辑数据集)
- [5.Step1X-Edit的预训练细节是什么](#5.Step1X-Edit的预训练细节是什么)
- [6.Step1X-Edit的架构是如何设计的？](#6.Step1X-Edit的架构是如何设计的？)

<h2 id="1.图像编辑模型涵盖哪些细粒度的编辑任务？">1.图像编辑模型涵盖哪些细粒度的编辑任务？?</h2>
图像编辑模型涵盖了多种细粒度的编辑任务，主要包括以下几类：

| 任务类别            | 具体内容                                                                                               |
|--------------------------------------|----------------------------------------------------------------------------------------------------------------------------|
| 内容编辑       | 对象的添加、删除、替换。                                                                                                   |
| 外观修改     | 颜色改变、材质修改(如青花瓷材质)、肖像美化、属性增强。                                                                   |
| 场景转换 | 背景替换、色调调整(色彩分级、去雾、去雨、季节转换)、光照调整。                                                           |
| 文本编辑             | 图像中文本修改、文字重绘、Logo/品牌替换(TOES→NIKE),支持中英文。                                                         |
| 风格迁移            | 输入图像风格抽取并迁移到新图像(线描、水彩、浮世绘、赛博朋克、胶片感等)。                                                 |
| 运动/姿态变换        | 姿态操控、人物动作变化、新颖视角合成(NVS)。                                                                              |
| 结构变换     | 几何结构调整、比例变化、身体/面部结构修改(瘦脸、延长腿部、局部形状改变等)。                                              |
| 换装                | 修改服饰款式、更换衣服、替换面料、保持人物身份一致。                                                                       |
| 人脸编辑              | 表情增强、五官调整、面部置换、身份保持编辑、数字人表情合成。                                                               |
| 光影增强                | 调整光源方向、强度、制造戏剧光、补光、逆光修复。                                                                            |
| 材质与质感增强 | 提升皮肤质感、物体表面质感、金属/玻璃/木材等材质变化。                                                                      |
| 分辨率增强        | 清晰度提升、细节补全、去噪、改善压缩损坏。                                                                                  |
| 视频一致性编辑 | 多帧一致性编辑、物体跟踪编辑、模板保持、跨帧风格或属性保持。                                                              |
| 多轮次编辑      | 多次编辑指令叠加、保持一致性、迭代生成历史记忆式编辑。                                                                     |
| 构图调整     | 裁剪、放大、改构图、视角转换、镜头焦距模拟(广角/长焦)。                                                                  |
| 电商图像增强     | 去除模特、衣物换色、产品精修、SKU合成、背景统一、电商风光影。                                                                                                                              |

<h2 id="2.图像编辑模型的主要技术路线有哪些？">2.图像编辑模型的主要技术路线有哪些？</h2>

目前主流的图像编辑模型主要采用以下几种技术路线：
| 模型名称        | 文本编码器 / 条件编码方式                         | 生成范式                               | 核心骨干网络                          |
|-----------------|---------------------------------------------------|----------------------------------------|---------------------------------------|
| Emu3.5          | 使用大语言模型分词器进行文本编码。                 | 自回归生成；通过并行预测技术加速推理。 | 大规模 Transformer 解码器，包含 64 层，并使用分组注意力与旋转位置编码。 |
| Qwen-Image      | 多模态模型作为条件编码器；同时使用图像编码器获取潜在表征。 | 基于流匹配的扩散生成。                 | 多模态扩散 Transformer；使用多尺度旋转位置编码以对齐图文位置。 |
| Step1X-Edit     | 多模态模型进行语义推理，输出图像编辑相关潜在条件。 | 基于整流流公式的扩散模型。             | 采用 DiT 结构，并通过连接器接收多模态模型提取的特征。 |
| FLUX.1 Kontext  | 使用专用文本编码器；在双流结构中分离处理文本与图像。 | 基于流匹配的扩散生成模型。             | 整流流 Transformer，包含双流块与融合块的组合结构。 |
| Seedream 4.0    | 使用视觉语言模型进行多模态理解。                   | 基于扩散模型；采用对抗式加速训练体系。 | 高效可扩展的 DiT 架构。               |

<h2 id="3.在图像编辑的定量评估中，常用的基准测试和性能指标是什么？">3.在图像编辑的定量评估中，常用的基准测试和性能指标是什么？</h2>

1. 关键基准测试:

- GEdit-Bench: 评估模型在 11 个不同类别下的真实世界用户指令编辑能力，支持英文（EN）和中文（CN）指令。

- ImgEdit: 涵盖 9 个常见编辑任务，共 734 个真实世界测试用例。
- KontextBench: 专注于上下文图像生成和编辑任务，包括文本编辑、局部编辑、全局编辑、风格参考和角色参考等六项任务。

- 此外，还有针对文本渲染的 CVTG-2K (英文) 和 ChineseWord (中文) 基准。

2. 评估指标:
通常采用 VIEScore 框架，由先进的 MLLM（如 GPT-4.1 或 Qwen2.5-VL）进行自动评估，分数范围为 0 到 10。主要指标包括：
- 语义一致性 (Semantic Consistency, SQ/SC): 衡量编辑结果与给定指令的符合程度。
- 感知质量 (Perceptual Quality, PQ): 评估图像的自然度和是否存在伪影。
- 总体得分 (Overall Score, O): 根据上述评估计算得出。

对于中文文本渲染，Qwen-Image 引入了基于字符级别的 准确率 (Accuracy)

<h2 id="4.Step1X-Edit-通用图像编辑框架是如何构建其大规模、多任务的编辑数据集">4.Step1X-Edit 通用图像编辑框架是如何构建其大规模、多任务的编辑数据集</h2>
Step1X-Edit 致力于构建一个涵盖 11 种多样化编辑任务（包含主体添加与删除、主体替换、背景替换、颜色变化、材质修改、动作姿态变化、肖像美化、色调转换、文本修改、风格迁移）的高质量数据集。该数据集的构造是一个多阶段的自动化和人工过滤管线，利用了多种先进的视觉工具：

1. 基础任务（主体增添/移除）：
- 对象定位与分割： 使用 Florence-2 进行对象标注和 SAM-2 进行分割。
- 指令生成： 通过 Step-1o 自动生成“从源图像到目标图像”的编辑指令（Instruction）。
2. 复杂内容操作（主体替换/背景改变）：
- 对象识别： 利用 Qwen2.5-VL 和 Recognize-Anything Model 来识别目标对象或关键词。
- 内容填充： 采用 Flux-Fill 进行内容感知修补/填充（inpainting）。
3. 高级编辑（材质修改）：
- 深度信息引入： 使用 ZeoDepth 进行深度估计。
- 条件控制生成： 结合 SD3.5 ControlNet，利用深度图和掩码等辅助信息，实现精确的材质或风格修改（例如，将龙虾材质改为青花瓷）。
4. 风格转移： 通过 SD3.5 ControlNet 和 边缘图像实现风格化注释和转换。

Step1X-Edit 的数据集通过这种混合工具链生成，然后经过严格的人工验证，确保了数据的高质量。

<h2 id="5.Step1X-Edit的预训练细节是什么">5.Step1X-Edit的预训练细节是什么</h2>

Step1X-Edit 的训练流程基于构建大规模、高质量的数据集和初始化策略：
1. 数据生成管线构建：
- 数据集目标： 团队设计了一个复杂的数据生成管线，旨在生产大规模、高质量的三元组（源图像、编辑指令、目标图像）。
- 规模与质量： 该管线共生成了超过 2000 万个三元组。经过 MLLM（例如 step-1o）和人工标注者的严格过滤（保留比例约为 20:1），最终保留了超过 **100 万个高质量三元组（Step1X-Edit-HQ）**用于训练。
- 任务覆盖： 数据集涵盖了 11 种不同的图像编辑子任务，包括主体增添/移除/替换、背景改变、颜色/材质修改、动作变化、色调转换、文本修改和风格转移等。
- 工具辅助： 数据构造利用了多种先进的视觉工具，例如 Florence-2 和 SAM-2 进行对象分割，Flux-Fill 进行内容感知修复，以及 ControlNet 和 Zeodepth 协助进行精确的材质或颜色修改。
2. 模型初始化与训练目标：
- 初始化： Step1X-Edit 的训练从一个文本到图像（T2I）模型开始，以确保保留模型已有的美学质量和视觉一致性。
- 训练目标： 模型通过优化扩散损失 (diffusion loss) 来训练，并遵循 整流流 (rectified flow) 公式进行生成。训练过程联合优化了连接器和下游的DiT网络

<h2 id="6.Step1X-Edit的架构是如何设计的？">6.Step1X-Edit的架构是如何设计的？</h2>
Step1X-Edit设计为一个统一的图像编辑模型，旨在紧密集成语义理解能力和图像生成能力，引入了多模态大语言模型。Step1X-Edit具体由三个关键组件构成：

1. 多模态大语言模型：
- 作用： MLLM（Qwen2.5-VL）用于处理参考图像和用户的编辑指令。它通过单次前向传播，联合捕获指令和视觉内容之间的语义关系。

- 指令特征提取： 模型在 MLLM 处理过程中，会选择性地丢弃与系统前缀相关的令牌嵌入。这样做是为了隔离并强调直接与编辑信息对齐的语义元素，确保后续处理能够精确聚焦于编辑要求。
2. 连接器模块：
- 作用： 这是一个轻量级模块，用于将 MLLM 提取的高级语义嵌入重构为紧凑的多模态特征表示。这些特征将用于指导下游的图像生成过程。
3. 扩散 Transformer (Diffusion in Transformer, DiT)：
- 骨干网络： Step1X-Edit 采用 DiT 风格的扩散架构作为图像解码器。
- 功能： DiT 接收由 MLLM 通过连接器提供的编辑条件，并生成目标图像的潜在嵌入 (latent embedding)，最终获得输出图像。

这种统一架构消除了在编辑过程中对额外掩码 (mask) 的要求，从而实现了无掩码的通用编辑。总而言之，Step1X-Edit 的设计目标是实现 MLLM-Diffusion 的无缝集成，解决传统方法中编辑指令遵循与图像保真度之间的矛盾。